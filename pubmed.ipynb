{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from urllib import parse\n",
    "\n",
    "# 设置驱动\n",
    "service = Service(executable_path='./chromedriver.exe')\n",
    "# 设置浏览器\n",
    "option = webdriver.ChromeOptions()\n",
    "option.binary_location = './chrome-win64/chrome.exe'\n",
    "# 浏览器添加EasyPubMedicine插件\n",
    "option.add_extension('./EasyPubMedicine.crx')\n",
    "\n",
    "browser = webdriver.Chrome(service=service,options=option)\n",
    "\n",
    "# 搜索关键词\n",
    "key_word = '(leukemia) AND (virus)AND(DNA damage)' \n",
    "# 设置年份\n",
    "min_year = '2010'\n",
    "max_year = '2025'\n",
    "# 爬取文章数量\n",
    "article_count = 200\n",
    "# 最小影响因子\n",
    "min_impact_factor = 8\n",
    "# 是否下载pdf\n",
    "download_pdf = True\n",
    "# 是否选择mate\n",
    "is_mate = False\n",
    "# 当前页数\n",
    "page = 1\n",
    "\n",
    "browser.get(f'https://pubmed.ncbi.nlm.nih.gov/?term={parse.quote(key_word)}&filter=years.{min_year}-{max_year}&page={page}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "# 过滤影响因子\n",
    "def fliter_if(min_if_value):\n",
    "    browser.find_element(By.XPATH,'//*[@id=\"imf-min\"]').clear()\n",
    "    browser.find_element(By.XPATH,'//*[@id=\"imf-min\"]').send_keys(str(min_if_value))\n",
    "    if browser.find_element(By.XPATH,'//*[@id=\"imf-activate\"]').is_displayed():\n",
    "        browser.find_element(By.XPATH,'//*[@id=\"imf-activate\"]').click()\n",
    "    else:\n",
    "        browser.find_element(By.XPATH,'//*[@id=\"imf-refresh\"]').click()\n",
    "    # 选择mate\n",
    "    if is_mate and not browser.find_element(By.XPATH,'//*[@id=\"id_filter_pubt.meta-analysis\"]').is_selected():\n",
    "        browser.find_element(By.XPATH,'//*[@id=\"static-filters-form\"]/div/div[1]/div[3]/ul/li[3]/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 导出文章信息\n",
    "def extract_list():\n",
    "    result = []\n",
    "    for article in browser.find_elements(By.XPATH,'//*[@id=\"search-results\"]/section/div[2]/div/article'):\n",
    "        if len(article.text.strip()) == 0:\n",
    "            continue\n",
    "        # 标题、作者、影响因子、pdf链接、文章链接\n",
    "        article_title = article.find_element(By.CLASS_NAME,'docsum-title').text\n",
    "        article_cite = article.find_element(By.CLASS_NAME,'full-authors').text\n",
    "        article_if = float(re.search('\\\\d+(\\\\.\\\\d)?',article.find_element(By.CLASS_NAME,'ep-if').text).group())\n",
    "        article_pdf = article.find_element(By.CLASS_NAME,'pdf').get_attribute('href')\n",
    "        article_url = article.find_element(By.CLASS_NAME,'docsum-title').get_attribute('href')\n",
    "        # if article_pdf is None:\n",
    "        #     continue\n",
    "        result.append((article_title.translate(str.maketrans('/\\\\|*><?:\"', '_________')),article_cite,article_if,article_pdf,article_url))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下一页\n",
    "def next():\n",
    "    global page\n",
    "    page = page + 1\n",
    "    browser.find_element(By.XPATH,'//*[@id=\"search-results\"]/div[6]/button[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from curl_cffi import requests\n",
    "\n",
    "#下载\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br'\n",
    "}\n",
    "def download(url,save_file):\n",
    "    timeout = 120\n",
    "    with open(save_file,'wb') as download_file:\n",
    "        try:\n",
    "            response = requests.get(url, impersonate=\"chrome101\", allow_redirects=True, timeout=timeout)\n",
    "            if response.status_code == httpx.codes.OK:\n",
    "                download_file.write(response.content)\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            response = httpx.get(url, headers = headers, follow_redirects=True, timeout=timeout)\n",
    "            if response.status_code == httpx.codes.OK:\n",
    "                download_file.write(response.content)\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            with httpx.stream(\"GET\", url, headers = headers, verify=False, timeout=timeout) as response:\n",
    "                if response.status_code == httpx.codes.OK:\n",
    "                    for chunk in response.iter_bytes():\n",
    "                        download_file.write(chunk)\n",
    "                    return True\n",
    "        except:\n",
    "            pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存的文章\n",
    "article_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start page 1\n",
      "PPM1D Mutations Drive Clonal Hematopoiesis in Response to Cytotoxic Chemotherapy. http://www.cell.com/article/S1934590918304855/pdf\n",
      "NF-kappaB-induced R-loop accumulation and DNA damage select for nucleotide excision repair deficiencies in adult T cell leukemia. https://www.pnas.org/doi/pdf/10.1073/pnas.2005568118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 保存路径\n",
    "save_path = './result'\n",
    "save_pdf_path = f'{save_path}/{key_word}'\n",
    "if not os.path.exists(save_pdf_path):\n",
    "    os.mkdir(save_pdf_path)\n",
    "\n",
    "def save_csv():\n",
    "    # 保存\n",
    "    article_df = pd.DataFrame(article_list,columns=['title','cite','if','url','pdf'])\n",
    "    article_df.to_csv(f'{save_path}/{key_word}.csv')\n",
    "\n",
    "# 开始爬取\n",
    "def start():\n",
    "    while(len(article_list) < article_count):\n",
    "        print(f'start page {page}')\n",
    "        fliter_if(min_impact_factor)\n",
    "        time.sleep(0.5)\n",
    "        tmp_list = extract_list()\n",
    "        for t in tmp_list:\n",
    "            title,cite,article_if,pdf,url = t\n",
    "            print(f'{title} {pdf}')\n",
    "            # 防止windows路径长度限制超过250\n",
    "            save_file = f'{save_pdf_path}/{title}'[0:100] + '.pdf'\n",
    "            if os.path.exists(save_file) or not download_pdf:\n",
    "                article_list.append([title,cite,article_if,url,pdf])\n",
    "            elif pdf is None:\n",
    "                article_list.append([title,cite,article_if,url,'无下载地址'])\n",
    "            else:\n",
    "                s = download(pdf,save_file)\n",
    "                article_list.append([title,cite,article_if,url,pdf if s else '下载失败'])\n",
    "        save_csv()\n",
    "        next()\n",
    "\n",
    "# 浏览器偶尔抽风，刷新重试\n",
    "retry = 3\n",
    "while retry >= 0:\n",
    "    try:\n",
    "        start()\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'重试{retry} {e}')\n",
    "        browser.refresh()\n",
    "        retry = retry - 1\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
